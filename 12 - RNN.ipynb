{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+TIeU+0swmLSEOFPuEPn8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaiminwoo0223/Deep-Learning/blob/main/12%20-%20RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kHzx0UngM6vj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden = 35\n",
        "lr = 0.01\n",
        "epochs = 1000"
      ],
      "metadata": {
        "id": "AP1380nPNLb4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용하는 문자는 영어 소문자 및 몇가지 특수문자로 제한한다.\n",
        "# alphabet(0-25), space(26), ... , start(0), end(1)\n",
        "\n",
        "string = \"i don't want a perfect life, i want a happy life!\"\n",
        "chars = \"abcdefghijklmnopqrstuvwxyz '!.,:;01\"\n",
        "\n",
        "char_list = [i for i in chars] # 문자열을 리스트로 바꾼다.\n",
        "n_letters = len(char_list)     # 문자의 개수를 저장한다.(문자열의 길이)"
      ],
      "metadata": {
        "id": "GJE7mmx2NQdt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(char_list)\n",
        "print(n_letters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JblTQuBlOcJu",
        "outputId": "af48dd5f-e87c-4b19-9d2b-44c9d3fc2fed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ', \"'\", '!', '.', ',', ':', ';', '0', '1']\n",
            "35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자를 그대로 쓰지 않고, one-hot 벡터로 바꿔서 연산한다.\n",
        "\n",
        "# start = [0 0 0 … 1 0]\n",
        "# a =     [1 0 0 … 0 0]\n",
        "# b =     [0 1 0 … 0 0]\n",
        "# c =     [0 0 1 … 0 0]\n",
        "# …\n",
        "# end =   [0 0 0 … 0 1]"
      ],
      "metadata": {
        "id": "kmGKCXLnO7s9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열을 one-hot 벡터의 스텍으로 만드는 함수\n",
        "def string_to_onehot(string):\n",
        "    # 시작 토큰과 끝 토큰을 만든다.\n",
        "    start = np.zeros(shape=n_letters, dtype=int) # [0 0 0 … 0 0]\n",
        "    end = np.zeros(shape=n_letters, dtype=int)   # [0 0 0 … 0 0]\n",
        "    start[-2] = 1                                # [0 0 0 … 1 0]\n",
        "    end[-1] = 1                                  # [0 0 0 … 0 1]\n",
        "\n",
        "    for i in string:\n",
        "        # 문자가 몇번째 문자인지 찾는다.(a:0, b:1, c:2, ...)\n",
        "        idx = char_list.index(i)\n",
        "        # 0으로만 구성된 배열을 만들어준다.([0 0 0 … 0 0])\n",
        "        zero = np.zeros(shape=n_letters, dtype=int)\n",
        "        # 해당 문자 인덱스만 1로 바꾼다.([1 0 0 … 0 0])\n",
        "        zero[idx] = 1\n",
        "        # start와 새로 생긴 zero를 붙이고, 이를 start에 할당합니다.\n",
        "        # 이것이 반복되면, start에는 문자를 one-hot 벡터로 바꾼 배열들이 점점 쌓여가게 된다.\n",
        "        start = np.vstack([start,zero])\n",
        "    # 문자열이 다 끝나면, 쌓아온 start와 end를 붙인다.\n",
        "    output = np.vstack([start,end])\n",
        "    return output"
      ],
      "metadata": {
        "id": "KDQLyyhBPkm6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot 벡터를 문자로 바꿔주는 함수\n",
        "def onehot_to_word(onehot_1):\n",
        "    # 텐서를 입력으로 받아, 넘파이 배열로 바꾼다.\n",
        "    onehot = torch.Tensor.numpy(onehot_1)\n",
        "    # one-hot 벡터의 최댓값(=1) 위치 인덱스로 문자를 찾습니다.\n",
        "    return char_list[onehot.argmax()]"
      ],
      "metadata": {
        "id": "kGNAdjSoTNMg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.act_fn = nn.Tanh()\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.act_fn(self.i2h(combined)) # hidden state 업데이트\n",
        "        output = self.i2o(combined)              # output\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size) # 아직 입력이 없을 때(t=0)의 hidden state를 초기화\n",
        "\n",
        "rnn = RNN(n_letters, n_hidden, n_letters)"
      ],
      "metadata": {
        "id": "-6tda6aEWeRt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수와 최적화\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "q0AzI5kKbxqF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor()) # 문자열 -> onehot 벡터 ->.토치 텐서\n",
        "\n",
        "for i in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    hidden = rnn.init_hidden() # 학습에 앞서, hidden state를 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    for j in range(one_hot.size()[0]-1):\n",
        "        input_ = one_hot[j:j+1,:] # 입력 = 앞글자(h e l l)\n",
        "        target = one_hot[j+1]    # 타겟 = 뒷글자(e l l o)\n",
        "        output, hidden = rnn.forward(input_, hidden)\n",
        "        loss = loss_func(output.view(-1), target.view(-1))\n",
        "        total_loss += loss\n",
        "\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    if i % 10 == 0:\n",
        "        print(total_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntfL_c9HbtxT",
        "outputId": "4318eb7e-a15b-44f9-d9f6-490d8013746e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.1465, grad_fn=<AddBackward0>)\n",
            "tensor(0.7718, grad_fn=<AddBackward0>)\n",
            "tensor(0.3392, grad_fn=<AddBackward0>)\n",
            "tensor(0.1822, grad_fn=<AddBackward0>)\n",
            "tensor(0.1043, grad_fn=<AddBackward0>)\n",
            "tensor(0.0721, grad_fn=<AddBackward0>)\n",
            "tensor(0.0617, grad_fn=<AddBackward0>)\n",
            "tensor(0.0580, grad_fn=<AddBackward0>)\n",
            "tensor(0.0566, grad_fn=<AddBackward0>)\n",
            "tensor(0.0725, grad_fn=<AddBackward0>)\n",
            "tensor(0.0570, grad_fn=<AddBackward0>)\n",
            "tensor(0.0540, grad_fn=<AddBackward0>)\n",
            "tensor(0.0494, grad_fn=<AddBackward0>)\n",
            "tensor(0.0564, grad_fn=<AddBackward0>)\n",
            "tensor(0.0443, grad_fn=<AddBackward0>)\n",
            "tensor(0.0452, grad_fn=<AddBackward0>)\n",
            "tensor(0.0372, grad_fn=<AddBackward0>)\n",
            "tensor(0.0330, grad_fn=<AddBackward0>)\n",
            "tensor(0.0306, grad_fn=<AddBackward0>)\n",
            "tensor(0.0292, grad_fn=<AddBackward0>)\n",
            "tensor(0.0281, grad_fn=<AddBackward0>)\n",
            "tensor(0.0271, grad_fn=<AddBackward0>)\n",
            "tensor(0.0291, grad_fn=<AddBackward0>)\n",
            "tensor(0.0295, grad_fn=<AddBackward0>)\n",
            "tensor(0.0252, grad_fn=<AddBackward0>)\n",
            "tensor(0.0214, grad_fn=<AddBackward0>)\n",
            "tensor(0.0273, grad_fn=<AddBackward0>)\n",
            "tensor(0.0191, grad_fn=<AddBackward0>)\n",
            "tensor(0.0131, grad_fn=<AddBackward0>)\n",
            "tensor(0.0220, grad_fn=<AddBackward0>)\n",
            "tensor(0.0140, grad_fn=<AddBackward0>)\n",
            "tensor(0.0086, grad_fn=<AddBackward0>)\n",
            "tensor(0.0059, grad_fn=<AddBackward0>)\n",
            "tensor(0.0043, grad_fn=<AddBackward0>)\n",
            "tensor(0.0105, grad_fn=<AddBackward0>)\n",
            "tensor(0.0063, grad_fn=<AddBackward0>)\n",
            "tensor(0.0041, grad_fn=<AddBackward0>)\n",
            "tensor(0.0029, grad_fn=<AddBackward0>)\n",
            "tensor(0.0021, grad_fn=<AddBackward0>)\n",
            "tensor(0.0015, grad_fn=<AddBackward0>)\n",
            "tensor(0.0129, grad_fn=<AddBackward0>)\n",
            "tensor(0.0028, grad_fn=<AddBackward0>)\n",
            "tensor(0.0017, grad_fn=<AddBackward0>)\n",
            "tensor(0.0010, grad_fn=<AddBackward0>)\n",
            "tensor(0.0007, grad_fn=<AddBackward0>)\n",
            "tensor(0.0005, grad_fn=<AddBackward0>)\n",
            "tensor(0.0004, grad_fn=<AddBackward0>)\n",
            "tensor(0.0004, grad_fn=<AddBackward0>)\n",
            "tensor(0.0003, grad_fn=<AddBackward0>)\n",
            "tensor(0.0003, grad_fn=<AddBackward0>)\n",
            "tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "tensor(0.0001, grad_fn=<AddBackward0>)\n",
            "tensor(0.0001, grad_fn=<AddBackward0>)\n",
            "tensor(0.0001, grad_fn=<AddBackward0>)\n",
            "tensor(0.0029, grad_fn=<AddBackward0>)\n",
            "tensor(0.0008, grad_fn=<AddBackward0>)\n",
            "tensor(0.0003, grad_fn=<AddBackward0>)\n",
            "tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "tensor(0.0001, grad_fn=<AddBackward0>)\n",
            "tensor(9.2192e-05, grad_fn=<AddBackward0>)\n",
            "tensor(8.0062e-05, grad_fn=<AddBackward0>)\n",
            "tensor(7.2901e-05, grad_fn=<AddBackward0>)\n",
            "tensor(6.7068e-05, grad_fn=<AddBackward0>)\n",
            "tensor(6.2100e-05, grad_fn=<AddBackward0>)\n",
            "tensor(5.7718e-05, grad_fn=<AddBackward0>)\n",
            "tensor(5.3825e-05, grad_fn=<AddBackward0>)\n",
            "tensor(5.0333e-05, grad_fn=<AddBackward0>)\n",
            "tensor(4.7198e-05, grad_fn=<AddBackward0>)\n",
            "tensor(4.7905e-05, grad_fn=<AddBackward0>)\n",
            "tensor(4.3409e-05, grad_fn=<AddBackward0>)\n",
            "tensor(3.9987e-05, grad_fn=<AddBackward0>)\n",
            "tensor(3.7597e-05, grad_fn=<AddBackward0>)\n",
            "tensor(3.5154e-05, grad_fn=<AddBackward0>)\n",
            "tensor(3.3365e-05, grad_fn=<AddBackward0>)\n",
            "tensor(3.1620e-05, grad_fn=<AddBackward0>)\n",
            "tensor(3.0036e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.8522e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.7149e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.5869e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.4676e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.3563e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.2963e-05, grad_fn=<AddBackward0>)\n",
            "tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "tensor(0.0008, grad_fn=<AddBackward0>)\n",
            "tensor(0.0003, grad_fn=<AddBackward0>)\n",
            "tensor(0.0001, grad_fn=<AddBackward0>)\n",
            "tensor(6.3407e-05, grad_fn=<AddBackward0>)\n",
            "tensor(3.1462e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.1799e-05, grad_fn=<AddBackward0>)\n",
            "tensor(1.8691e-05, grad_fn=<AddBackward0>)\n",
            "tensor(1.7011e-05, grad_fn=<AddBackward0>)\n",
            "tensor(1.6165e-05, grad_fn=<AddBackward0>)\n",
            "tensor(1.5459e-05, grad_fn=<AddBackward0>)\n",
            "tensor(1.4926e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.2457e-05, grad_fn=<AddBackward0>)\n",
            "tensor(0.0015, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "start = torch.zeros(1, n_letters)\n",
        "start[:, -2] = 1\n",
        "\n",
        "with torch.no_grad():\n",
        "    hidden = rnn.init_hidden()\n",
        "    input_ = start\n",
        "    output_string = \"\"\n",
        "\n",
        "    for i in range(len(string)):\n",
        "        output, hidden = rnn.forward(input_, hidden)\n",
        "        output_string += onehot_to_word(output.data)\n",
        "        input_ = output\n",
        "\n",
        "print(output_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPv03WHpigPe",
        "outputId": "46a9da9c-df32-439c-8a26-2975a7886002"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i don't want a perfect life, i want a happy life!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rnBSHIp1ofWh"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}