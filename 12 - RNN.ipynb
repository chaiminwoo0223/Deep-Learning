{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmCF3RHxNPOOK3KqVsKfwZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaiminwoo0223/Deep-Learning/blob/main/12%20-%20RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kHzx0UngM6vj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_hidden = 35\n",
        "lr = 0.01\n",
        "epochs = 1000"
      ],
      "metadata": {
        "id": "AP1380nPNLb4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용하는 문자는 영어 소문자 및 몇가지 특수문자로 제한한다.\n",
        "# alphabet(0-25), space(26), ... , start(0), end(1)\n",
        "\n",
        "string = \"i don't want a perfect life, i want a happy life!\"\n",
        "chars = \"abcdefghijklmnopqrstuvwxyz '!.,:;01\"\n",
        "\n",
        "char_list = [i for i in chars] # 문자열을 리스트로 바꾼다.\n",
        "n_letters = len(char_list)     # 문자의 개수를 저장한다.(문자열의 길이)"
      ],
      "metadata": {
        "id": "GJE7mmx2NQdt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(char_list)\n",
        "print(n_letters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JblTQuBlOcJu",
        "outputId": "7ab6e801-a30a-4452-ee38-c5658013bffb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ', \"'\", '!', '.', ',', ':', ';', '0', '1']\n",
            "35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자를 그대로 쓰지 않고, one-hot 벡터로 바꿔서 연산한다.\n",
        "\n",
        "# start = [0 0 0 … 1 0]\n",
        "# a =     [1 0 0 … 0 0]\n",
        "# b =     [0 1 0 … 0 0]\n",
        "# c =     [0 0 1 … 0 0]\n",
        "# …\n",
        "# end =   [0 0 0 … 0 1]"
      ],
      "metadata": {
        "id": "kmGKCXLnO7s9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문자열을 one-hot 벡터의 스텍으로 만드는 함수\n",
        "def string_to_onehot(string):\n",
        "    # 시작 토큰과 끝 토큰을 만든다.\n",
        "    start = np.zeros(shape=n_letters, dtype=int) # [0 0 0 … 0 0]\n",
        "    end = np.zeros(shape=n_letters, dtype=int)   # [0 0 0 … 0 0]\n",
        "    start[-2] = 1                                # [0 0 0 … 1 0]\n",
        "    end[-1] = 1                                  # [0 0 0 … 0 1]\n",
        "\n",
        "    for i in string:\n",
        "        # 문자가 몇번째 문자인지 찾는다.(a:0, b:1, c:2, ...)\n",
        "        idx = char_list.index(i)\n",
        "        # 0으로만 구성된 배열을 만들어준다.([0 0 0 … 0 0])\n",
        "        zero = np.zeros(shape=n_letters, dtype=int)\n",
        "        # 해당 문자 인덱스만 1로 바꾼다.([1 0 0 … 0 0])\n",
        "        zero[idx] = 1\n",
        "        # start와 새로 생긴 zero를 붙이고, 이를 start에 할당한다.\n",
        "        # 이것이 반복되면, start에는 문자를 one-hot 벡터로 바꾼 배열들이 점점 쌓여가게 된다.\n",
        "        start = np.vstack([start,zero])\n",
        "    # 문자열이 다 끝나면, 쌓아온 start와 end를 붙인다.\n",
        "    output = np.vstack([start,end])\n",
        "    return output"
      ],
      "metadata": {
        "id": "KDQLyyhBPkm6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot 벡터를 문자로 바꿔주는 함수\n",
        "def onehot_to_word(onehot_1):\n",
        "    # 텐서를 입력으로 받아, 넘파이 배열로 바꾼다.\n",
        "    onehot = torch.Tensor.numpy(onehot_1)\n",
        "    # one-hot 벡터의 최댓값(=1) 위치 인덱스로 문자를 찾습니다.\n",
        "    return char_list[onehot.argmax()]"
      ],
      "metadata": {
        "id": "kGNAdjSoTNMg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.act_fn = nn.Tanh()\n",
        "\n",
        "    def forward(self, input_, hidden):\n",
        "        combined = torch.cat((input_, hidden), 1)\n",
        "        hidden = self.act_fn(self.i2h(combined)) # hidden state 업데이트\n",
        "        output = self.i2o(combined)              # output\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size) # 아직 입력이 없을 때(t=0)의 hidden state를 초기화\n",
        "\n",
        "rnn = RNN(n_letters, n_hidden, n_letters)"
      ],
      "metadata": {
        "id": "-6tda6aEWeRt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수와 최적화\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "q0AzI5kKbxqF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor()) # 문자열 -> onehot 벡터 ->.토치 텐서\n",
        "\n",
        "for i in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    hidden = rnn.init_hidden() # 학습에 앞서, hidden state를 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    for j in range(one_hot.size()[0]-1):\n",
        "        input_ = one_hot[j:j+1,:] # 입력 = 앞글자(h e l l)\n",
        "        target = one_hot[j+1]    # 타겟 = 뒷글자(e l l o)\n",
        "        output, hidden = rnn.forward(input_, hidden)\n",
        "        loss = loss_func(output.view(-1), target.view(-1))\n",
        "        total_loss += loss\n",
        "\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    if i % 10 == 0:\n",
        "        print(total_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntfL_c9HbtxT",
        "outputId": "af9b3dfc-c724-4a2b-f913-291c66c4d104"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.9194, grad_fn=<AddBackward0>)\n",
            "tensor(0.6693, grad_fn=<AddBackward0>)\n",
            "tensor(0.3048, grad_fn=<AddBackward0>)\n",
            "tensor(0.1727, grad_fn=<AddBackward0>)\n",
            "tensor(0.1030, grad_fn=<AddBackward0>)\n",
            "tensor(0.0761, grad_fn=<AddBackward0>)\n",
            "tensor(0.0652, grad_fn=<AddBackward0>)\n",
            "tensor(0.0608, grad_fn=<AddBackward0>)\n",
            "tensor(0.0586, grad_fn=<AddBackward0>)\n",
            "tensor(0.0601, grad_fn=<AddBackward0>)\n",
            "tensor(0.0575, grad_fn=<AddBackward0>)\n",
            "tensor(0.0541, grad_fn=<AddBackward0>)\n",
            "tensor(0.0477, grad_fn=<AddBackward0>)\n",
            "tensor(0.0412, grad_fn=<AddBackward0>)\n",
            "tensor(0.0367, grad_fn=<AddBackward0>)\n",
            "tensor(0.0309, grad_fn=<AddBackward0>)\n",
            "tensor(0.0284, grad_fn=<AddBackward0>)\n",
            "tensor(0.0309, grad_fn=<AddBackward0>)\n",
            "tensor(0.0278, grad_fn=<AddBackward0>)\n",
            "tensor(0.0254, grad_fn=<AddBackward0>)\n",
            "tensor(0.0228, grad_fn=<AddBackward0>)\n",
            "tensor(0.0190, grad_fn=<AddBackward0>)\n",
            "tensor(0.0243, grad_fn=<AddBackward0>)\n",
            "tensor(0.0153, grad_fn=<AddBackward0>)\n",
            "tensor(0.0161, grad_fn=<AddBackward0>)\n",
            "tensor(0.0084, grad_fn=<AddBackward0>)\n",
            "tensor(0.0053, grad_fn=<AddBackward0>)\n",
            "tensor(0.0045, grad_fn=<AddBackward0>)\n",
            "tensor(0.0044, grad_fn=<AddBackward0>)\n",
            "tensor(0.0030, grad_fn=<AddBackward0>)\n",
            "tensor(0.0022, grad_fn=<AddBackward0>)\n",
            "tensor(0.0061, grad_fn=<AddBackward0>)\n",
            "tensor(0.0026, grad_fn=<AddBackward0>)\n",
            "tensor(0.0021, grad_fn=<AddBackward0>)\n",
            "tensor(0.0036, grad_fn=<AddBackward0>)\n",
            "tensor(0.0019, grad_fn=<AddBackward0>)\n",
            "tensor(0.0014, grad_fn=<AddBackward0>)\n",
            "tensor(0.0010, grad_fn=<AddBackward0>)\n",
            "tensor(0.0009, grad_fn=<AddBackward0>)\n",
            "tensor(0.0008, grad_fn=<AddBackward0>)\n",
            "tensor(0.0148, grad_fn=<AddBackward0>)\n",
            "tensor(0.0039, grad_fn=<AddBackward0>)\n",
            "tensor(0.0024, grad_fn=<AddBackward0>)\n",
            "tensor(0.0017, grad_fn=<AddBackward0>)\n",
            "tensor(0.0012, grad_fn=<AddBackward0>)\n",
            "tensor(0.0010, grad_fn=<AddBackward0>)\n",
            "tensor(0.0008, grad_fn=<AddBackward0>)\n",
            "tensor(0.0066, grad_fn=<AddBackward0>)\n",
            "tensor(0.0040, grad_fn=<AddBackward0>)\n",
            "tensor(0.0018, grad_fn=<AddBackward0>)\n",
            "tensor(0.0012, grad_fn=<AddBackward0>)\n",
            "tensor(0.0009, grad_fn=<AddBackward0>)\n",
            "tensor(0.0007, grad_fn=<AddBackward0>)\n",
            "tensor(0.0006, grad_fn=<AddBackward0>)\n",
            "tensor(0.0005, grad_fn=<AddBackward0>)\n",
            "tensor(0.0004, grad_fn=<AddBackward0>)\n",
            "tensor(0.0009, grad_fn=<AddBackward0>)\n",
            "tensor(0.0009, grad_fn=<AddBackward0>)\n",
            "tensor(0.0005, grad_fn=<AddBackward0>)\n",
            "tensor(0.0004, grad_fn=<AddBackward0>)\n",
            "tensor(0.0003, grad_fn=<AddBackward0>)\n",
            "tensor(0.0003, grad_fn=<AddBackward0>)\n",
            "tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "tensor(0.0001, grad_fn=<AddBackward0>)\n",
            "tensor(0.0001, grad_fn=<AddBackward0>)\n",
            "tensor(0.0001, grad_fn=<AddBackward0>)\n",
            "tensor(0.0034, grad_fn=<AddBackward0>)\n",
            "tensor(0.0006, grad_fn=<AddBackward0>)\n",
            "tensor(0.0002, grad_fn=<AddBackward0>)\n",
            "tensor(0.0001, grad_fn=<AddBackward0>)\n",
            "tensor(0.0001, grad_fn=<AddBackward0>)\n",
            "tensor(9.1348e-05, grad_fn=<AddBackward0>)\n",
            "tensor(8.2610e-05, grad_fn=<AddBackward0>)\n",
            "tensor(7.5537e-05, grad_fn=<AddBackward0>)\n",
            "tensor(6.9560e-05, grad_fn=<AddBackward0>)\n",
            "tensor(6.4332e-05, grad_fn=<AddBackward0>)\n",
            "tensor(5.9846e-05, grad_fn=<AddBackward0>)\n",
            "tensor(5.5830e-05, grad_fn=<AddBackward0>)\n",
            "tensor(5.2216e-05, grad_fn=<AddBackward0>)\n",
            "tensor(4.8947e-05, grad_fn=<AddBackward0>)\n",
            "tensor(4.5973e-05, grad_fn=<AddBackward0>)\n",
            "tensor(4.3259e-05, grad_fn=<AddBackward0>)\n",
            "tensor(4.0772e-05, grad_fn=<AddBackward0>)\n",
            "tensor(3.8488e-05, grad_fn=<AddBackward0>)\n",
            "tensor(3.6661e-05, grad_fn=<AddBackward0>)\n",
            "tensor(0.0004, grad_fn=<AddBackward0>)\n",
            "tensor(0.0007, grad_fn=<AddBackward0>)\n",
            "tensor(0.0003, grad_fn=<AddBackward0>)\n",
            "tensor(0.0001, grad_fn=<AddBackward0>)\n",
            "tensor(5.0765e-05, grad_fn=<AddBackward0>)\n",
            "tensor(4.4192e-05, grad_fn=<AddBackward0>)\n",
            "tensor(3.3969e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.9875e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.7182e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.5486e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.3872e-05, grad_fn=<AddBackward0>)\n",
            "tensor(2.2527e-05, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "start = torch.zeros(1, n_letters)\n",
        "start[:, -2] = 1\n",
        "\n",
        "with torch.no_grad():\n",
        "    hidden = rnn.init_hidden()\n",
        "    input_ = start\n",
        "    output_string = \"\"\n",
        "\n",
        "    for i in range(len(string)):\n",
        "        output, hidden = rnn.forward(input_, hidden)\n",
        "        output_string += onehot_to_word(output.data)\n",
        "        input_ = output\n",
        "\n",
        "print(output_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPv03WHpigPe",
        "outputId": "8f4b4c4e-e10e-4e86-d0e7-354f6a2a1aa8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i don't want a perfect life, i want a hapeyy lrfa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = np.zeros(shape=n_letters, dtype=int)\n",
        "start[-2] = 1\n",
        "start"
      ],
      "metadata": {
        "id": "rnBSHIp1ofWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6cba71-36eb-4412-bfd0-0846972f5a66"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = torch.zeros(1, n_letters)\n",
        "start[:, -2] = 1\n",
        "start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nRxhrjKDrGN",
        "outputId": "2aaeff92-fad9-497c-d4b2-441f55967962"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-MDcHI3VDx3b"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}