{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNTID8/YHGhZdScn+gyoCM4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaiminwoo0223/Deep-Learning/blob/main/15%20-%20Char_RNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Download"
      ],
      "metadata": {
        "id": "oLnBllwULxVX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxjNI_HULrED",
        "outputId": "1ac49475-1455-472e-ba9a-88122ea50357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-08 12:00:04--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘./data/input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.006s  \n",
            "\n",
            "2023-05-08 12:00:04 (172 MB/s) - ‘./data/input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!rm -r data\n",
        "import os \n",
        "\n",
        "try:\n",
        "  os.mkdir(\"./data\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI2sdvEPMJ_T",
        "outputId": "ffbf9519-ddcc-4bb8-afdc-84f2dc32ffc2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Using cached Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "Installing collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "70OtbL2XLxXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math"
      ],
      "metadata": {
        "id": "_VK6W1d5MKBV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter"
      ],
      "metadata": {
        "id": "WqWJV8upLxZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 10\n",
        "chunk_len = 200\n",
        "hidden_size = 100\n",
        "batch_size = 1\n",
        "num_layers = 1\n",
        "embedding_size = 70\n",
        "lr = 0.002"
      ],
      "metadata": {
        "id": "zYITPMa-MKDo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "## 1.Prepare Characters"
      ],
      "metadata": {
        "id": "ZLN5AUaQLxbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print(\"num_chars =\", n_characters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyNL_napMKIr",
        "outputId": "14d73c6e-4001-4dec-f720-15c5285fa238"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
            "\r\u000b\f\n",
            "num_chars = 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Get Text Data"
      ],
      "metadata": {
        "id": "SUA03o4nLxd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = unidecode.unidecode(open('./data/input.txt').read())\n",
        "file_len = len(file)\n",
        "print(\"file_len =\", file_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vXnA3qkMKLG",
        "outputId": "22c1c3dc-f4f4-419b-ed50-e44a51890400"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file_len = 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions For Text Processing\n",
        "## 1.Random Chunk"
      ],
      "metadata": {
        "id": "O4HW7Ny5LxgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_chunk():\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dVnuwLBMKNT",
        "outputId": "c101b777-6d80-4502-8889-1226e45e2cca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hither bear your treasure and your goods.\n",
            "For my part, I'll resign unto your grace\n",
            "The seal I keep: and so betide to me\n",
            "As well I tender you and all of yours!\n",
            "Come, I'll conduct you to the sanctuary.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Character To Tensor"
      ],
      "metadata": {
        "id": "Cjym5849Lxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "    return tensor\n",
        "print(char_tensor('ABCdef'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z20KrxgfMKU5",
        "outputId": "b5e2e807-415d-4686-db9b-603bd7f6d1aa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36, 37, 38, 13, 14, 15])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Chunk Into Input & Label"
      ],
      "metadata": {
        "id": "ckZwyCSJMATC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_training_set():\n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "metadata": {
        "id": "4iZjNQolMuLM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM\n",
        "\n",
        "## 1.Model"
      ],
      "metadata": {
        "id": "hIEnp40PMAVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers = 1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
        "        self.rnn = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers)\n",
        "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
        "    \n",
        "    def forward(self, input, hidden, cell):\n",
        "        out = self.encoder(input.view(1,-1))\n",
        "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
        "        out = self.decoder(out.view(batch_size,-1))\n",
        "        return out, hidden, cell\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return hidden, cell\n",
        "\n",
        "model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)      "
      ],
      "metadata": {
        "id": "Wx3OxzulM2XK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = char_tensor(\"A\")\n",
        "print(inp)\n",
        "hidden, cell = model.init_hidden()\n",
        "print(hidden.size())\n",
        "out, hidden, cell = model(inp, hidden, cell)\n",
        "print(out.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQdEOHY_M9C5",
        "outputId": "7b578cd6-6925-4356-e0bb-9ad619c415ce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([36])\n",
            "torch.Size([1, 1, 100])\n",
            "torch.Size([1, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Loss & Optimizer"
      ],
      "metadata": {
        "id": "EkiqF7fwMAXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "XcjkVk92M9o9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Test Function"
      ],
      "metadata": {
        "id": "ZPzRJztdMFfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    start_str = \"b\"\n",
        "    inp = char_tensor(start_str)\n",
        "    hidden, cell = model.init_hidden()\n",
        "    x = inp\n",
        "    print(start_str, end=\"\")\n",
        "\n",
        "    for i in range(200):\n",
        "        output, hidden, cell = model(x, hidden, cell)\n",
        "        output_dist = output.data.view(-1).div(0.8).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        predicted_char = all_characters[top_i]\n",
        "        print(predicted_char, end=\"\")\n",
        "        x = char_tensor(predicted_char)"
      ],
      "metadata": {
        "id": "5TdGv0VuNARx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "XyDP2Vd7MG81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epochs):\n",
        "    inp, label = random_training_set() # 랜덤한 텍스트 덩어리를 샘플링하고, 이를 텐서로 변환한다.\n",
        "    hidden, cell = model.init_hidden()\n",
        "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for j in range(chunk_len-1):\n",
        "        x = inp[j]\n",
        "        y_= label[j].unsqueeze(0).type(torch.LongTensor)\n",
        "        y, hidden, cell = model(x, hidden, cell)\n",
        "        loss += loss_func(y, y_)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(\"\\n\", loss/chunk_len, \"\\n\")\n",
        "        test()\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7qnSuM_NCTH",
        "outputId": "04484c4d-7f09-40ec-d8b6-2bc642cc8114"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " tensor([4.5762], grad_fn=<DivBackward0>) \n",
            "\n",
            "b^%z@h\rQWhkOgL(FiU^P^oc:]z2GXo#R'O^E6<vtKjcPyU!axDL/o#znV}x!9nL{e7.ib[`MP6F5|GIerm,19b|m&CwvXR;>A|OT*>^wpw9 \n",
            "@}6uNo\n",
            "aL\"XDM[9\\YU0m6#R{s$b[7/lCT7skv0>U<2:\rT#r[QVvbW?7XJP&y5hKY_7)V+\t,3ycy~+BMh.01nRN,/6Zaf\n",
            "\n",
            "\n",
            " tensor([2.7900], grad_fn=<DivBackward0>) \n",
            "\n",
            "blono bis Iy onceer the in  bhes tlk gSt sov fy mamth erere mo, the spas art to mherer he bithe swhinodrwrl tacha is weri teedan gorlt lat lher moe che toufird  ale sit arthe or m It\n",
            "swoutd ir thhas Sa\n",
            "\n",
            "\n",
            " tensor([2.3730], grad_fn=<DivBackward0>) \n",
            "\n",
            "bmee tore lis wninmen0ing, blthanend the yowi ndom Rpin wins worerlende that fears dot loth loflul\n",
            "That for phis ofYlenet asge ing arteind be lifrtisd the me, whot my mome-heat whirnd cof sealat ise sa\n",
            "\n",
            "\n",
            " tensor([2.2643], grad_fn=<DivBackward0>) \n",
            "\n",
            "bma'd hass our the of then zouy famut the beart sawh me pliry soJ ther.\n",
            "Ring tiis an you, this:\n",
            "Thou hare thert me the thurting:\n",
            "Whale minde,\n",
            "\n",
            "OIN:\n",
            "INor oullll id Lome the fertim win lo soit may of the\n",
            "\n",
            "\n",
            " tensor([2.2994], grad_fn=<DivBackward0>) \n",
            "\n",
            "bed las a fard,\n",
            "Acoll we cartrebefer of Yo courdinge yor to sen weenth and worse, thes youse; ta bame, we prarle thith hery catet ye dore band spis are dreet.\n",
            "\n",
            "Di.\n",
            "\n",
            "jCINV ERION:\n",
            "\n",
            "HoRUWGI:\n",
            "Set and, hast\n",
            "\n",
            "\n",
            " tensor([2.3134], grad_fn=<DivBackward0>) \n",
            "\n",
            "ble some tay it themper mere car lood Vase mord comech sofd, is aR all diledne pean you buact tourgLThene beet and the to gen of to pad, wheming coten mian warircay of or thee me hat, to spathet,\n",
            "Is he\n",
            "\n",
            "\n",
            " tensor([2.1128], grad_fn=<DivBackward0>) \n",
            "\n",
            "b I han: the you shius buth to kell whes herout\n",
            "I not ince oft verenes to wein the thou the pore, gote thay;\n",
            "A prebpere hath hell maest not soonour tataing ances, bures for we'd to and,\n",
            "An thave a thau\n",
            "\n",
            "\n",
            " tensor([2.2280], grad_fn=<DivBackward0>) \n",
            "\n",
            "blay of come, I with him the faind a the ththe and she biend and muod her unowh and whark of eftinm and and the with thos the be mere igt onet rengt.\n",
            "Pend ar hid have, unt\n",
            "The lave bele fonst your blou\n",
            "\n",
            "\n",
            " tensor([2.0830], grad_fn=<DivBackward0>) \n",
            "\n",
            "brour uf Ra a former coore a itengor gordenes ding ceantould catince frand, wo comens fatincangs to yor pome ancayed beis dingeks a is, seat foover I whike Cis beacer'd haken. in, and frath I shult mo \n",
            "\n",
            "\n",
            " tensor([2.0751], grad_fn=<DivBackward0>) \n",
            "\n",
            "buns whome ney to qurteds\n",
            "To prantereg, and mearen of as to he deangs in inoner;\n",
            "On at stinger wet dael, slo' the that are be ofes the thep in the pressive,\n",
            "The so forls? I wisike the geese, fell hinfo\n",
            "\n",
            "\n",
            " tensor([2.3378], grad_fn=<DivBackward0>) \n",
            "\n",
            "becy buth mewe, I say the mondy montine, swen proms fake haster\n",
            "To pust so cold not to rats weare hougly and spo call buthor boor me him, the not thou\n",
            "And alage not bay his wlore and be por modound wit\n",
            "\n",
            "\n",
            " tensor([2.0471], grad_fn=<DivBackward0>) \n",
            "\n",
            "ble face a\n",
            "To goods shand is is be will\n",
            "That to of fullige tell me me thou stroned to growldness o hathere the reach in will eand ather'd in haus it nors the sheronbems him tok olf swain that core a co\n",
            "\n",
            "\n",
            " tensor([2.1573], grad_fn=<DivBackward0>) \n",
            "\n",
            "bust\n",
            "To gration me.\n",
            "\n",
            "AY RONGERLO:\n",
            "In thich is fortion of to then you the thensem.\n",
            "\n",
            "KENBARS IANNET:\n",
            "There Cilling the mile mey ting you dowait\n",
            "Me deing sir thou to awive.\n",
            "Whith duer:\n",
            "But hide combret, y\n",
            "\n",
            "\n",
            " tensor([1.8629], grad_fn=<DivBackward0>) \n",
            "\n",
            "bloy ade lourter gores\n",
            "Yen for trace well hank\n",
            "\n",
            "POLO:\n",
            "Butther not in ther him here\n",
            "I the crom gake here hald of hampebind hoursher thou deerheremes thesean for the hay not it the mind, ho ham;\n",
            "And make\n",
            "\n",
            "\n",
            " tensor([2.0368], grad_fn=<DivBackward0>) \n",
            "\n",
            "ba\n",
            "The lave you force thee the make and sar to meens,\n",
            "Frow frone benet, an in me ear the but marceny the is sfoor an hide the\n",
            "racis the lood would a pusers he now tome angay frith\n",
            "at and fort ther, hon\n",
            "\n",
            "\n",
            " tensor([1.9071], grad_fn=<DivBackward0>) \n",
            "\n",
            "brown dest: the citherry not mon heris\n",
            "A. Vured dich canch I raused well contster sofe.\n",
            "\n",
            "CATHARD IUS:\n",
            "My sirst then in the is him house.\n",
            "\n",
            "LARENG:\n",
            "How our and Rome maarts sire;\n",
            "Wis ecchard your call fom\n",
            "\n",
            "\n",
            " tensor([1.7915], grad_fn=<DivBackward0>) \n",
            "\n",
            "by I reaks\n",
            "That greame and me not a be me\n",
            "Roich'd so hear mappll our to not y nim is sising we me to the for, and to with for be be the king peak.\n",
            "\n",
            "YUS:\n",
            "Whand, but whith a rath of whot all souts:\n",
            "But w\n",
            "\n",
            "\n",
            " tensor([1.7863], grad_fn=<DivBackward0>) \n",
            "\n",
            "bfet.\n",
            "\n",
            "Forst thernot Go dest nod by were ale and so soald my.\n",
            "\n",
            "GLOUCENS ELIO:\n",
            "I yet nave is the have remay,\n",
            "Prest and enghing the has befors,\n",
            "Nod is sictain, my of the not by you blecht thous uppand.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " tensor([1.9496], grad_fn=<DivBackward0>) \n",
            "\n",
            "bre?\n",
            "I oft what a more theat the her puar to so was that lightort\n",
            "To that ales and prone; myruiness thee neft\n",
            "And the selled a days, here a chy to mied\n",
            "To came; have your from hate O ast of to be the g\n",
            "\n",
            "\n",
            " tensor([1.9260], grad_fn=<DivBackward0>) \n",
            "\n",
            "bly resinos I hust so nith dear puse his brees's ungned bears ind os the with him, wore to will thou nid lide,\n",
            "Mis sirnd tisfal of, as is lost the firt;\n",
            "And, were not with siry Caminese of to dow the b\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r49TiosfNCvZ"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}