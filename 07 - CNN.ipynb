{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMId0cb+Wvs7tTddL+RBzoH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaiminwoo0223/Deep-Learning/blob/main/07%20-%20CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "S-RkvnRBEpvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_nfl8hEjEvtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST 데이터"
      ],
      "metadata": {
        "id": "ia5ZCFwEHPFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.데이터 다운로드"
      ],
      "metadata": {
        "id": "a2pk9PIlIsV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(\"../\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)"
      ],
      "metadata": {
        "id": "z5p7fZOFFosi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Size"
      ],
      "metadata": {
        "id": "R96pMPYKJDU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "kHNrvsRjHYRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_dataset.__getitem__(0)\n",
        "print(image.size(), label)"
      ],
      "metadata": {
        "id": "B-Nm8yNLHp_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_dataset[0]\n",
        "print(image.size(), label)"
      ],
      "metadata": {
        "id": "4uv8F2Z9JW0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Length"
      ],
      "metadata": {
        "id": "HFn4yBs2JMeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.__len__())"
      ],
      "metadata": {
        "id": "pR3HSuz3IyQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "id": "46gN9VMDIaA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Show"
      ],
      "metadata": {
        "id": "v-CuMxcrJ53q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    img = train_dataset[i][0].numpy()\n",
        "    plt.imshow(img[0], cmap='gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "jNsxpG3IJ939"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Layer"
      ],
      "metadata": {
        "id": "eX2MRkAPK54k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Channels"
      ],
      "metadata": {
        "id": "FQpMGjffMG6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image,label = train_dataset[0]\n",
        "# nn.Conv2d연산을 적용할 수 있도록, 이미지 데이터의 형태를 변환\n",
        "image = image.view(-1, image.size()[0], image.size()[1], image.size()[2])\n",
        "image.size()"
      ],
      "metadata": {
        "id": "adNtWPF0Link"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1개의 채널을 받아서, 3개의 채널이 나오는 컨볼루션 연산을 정의\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
        "# 입력 이미지\n",
        "output = conv_layer(image)\n",
        "print(output.size())"
      ],
      "metadata": {
        "id": "5KGaloH_M-Kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(output.size()[1]):\n",
        "    plt.imshow(output[0,i,:,:].data.numpy(), cmap='gray', vmin=-1, vmax=1)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8lZSLhLgOeHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Kernel Size\n",
        "- 커널의 크기가 어떤 역할을 하는가?"
      ],
      "metadata": {
        "id": "gtQ_ABUGQsul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 커널 사이즈 = 1\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1)\n",
        "output = conv_layer(image)\n",
        "plt.imshow(output[0,0,:,:].data.numpy(), cmap='gray')\n",
        "plt.show()\n",
        "print(\"커널 사이즈가 1인 경우 결과값의 크기 : {}\".format(output.size()))\n",
        "# 커널 사이즈 = 3\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n",
        "output = conv_layer(image)\n",
        "plt.imshow(output[0,0,:,:].data.numpy(), cmap='gray')\n",
        "plt.show()\n",
        "print(\"커널 사이즈가 3인 경우 결과값의 크기 : {}\".format(output.size()))\n",
        "# 커널 사이즈 = 5\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=5)\n",
        "output = conv_layer(image)\n",
        "plt.imshow(output[0,0,:,:].data.numpy(), cmap='gray')\n",
        "plt.show()\n",
        "print(\"커널 사이즈가 5인 경우 결과값의 크기 : {}\".format(output.size()))"
      ],
      "metadata": {
        "id": "ipCzjxK2Q4Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Stride\n",
        "- 스트라이드가 어떤 역할을 하는가?"
      ],
      "metadata": {
        "id": "s7gJOPHVSjj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 스트라이드 = 1\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, stride=1)\n",
        "output = conv_layer(image)\n",
        "plt.imshow(output[0,0,:,:].data.numpy(), cmap='gray')\n",
        "plt.show()\n",
        "print(\"스트라이드가 1인 경우 결과값의 크기 : {}\".format(output.size()))\n",
        "# 스트라이드 = 3\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, stride=3)\n",
        "output = conv_layer(image)\n",
        "plt.imshow(output[0,0,:,:].data.numpy(), cmap='gray')\n",
        "plt.show()\n",
        "print(\"스트라이드가 3인 경우 결과값의 크기 : {}\".format(output.size()))\n",
        "# 스트라이드 = 5\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, stride=5)\n",
        "output = conv_layer(image)\n",
        "plt.imshow(output[0,0,:,:].data.numpy(), cmap='gray')\n",
        "plt.show()\n",
        "print(\"스트라이드가 5인 경우 결과값의 크기 : {}\".format(output.size()))"
      ],
      "metadata": {
        "id": "TRujN-Q4R4wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Padding\n",
        "- 패딩이 어떤 역할을 하는가?"
      ],
      "metadata": {
        "id": "k8ddYxXmUWTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩 = 0\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, padding=0)\n",
        "output = conv_layer(image)\n",
        "plt.imshow(output[0,0,:,:].data.numpy(), cmap='gray')\n",
        "plt.show()\n",
        "print(\"패딩이 0인 경우 결과값의 크기 : {}\".format(output.size()))\n",
        "# 패딩 = 1\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, padding=1)\n",
        "output = conv_layer(image)\n",
        "plt.imshow(output[0,0,:,:].data.numpy(), cmap='gray')\n",
        "plt.show()\n",
        "print(\"패딩이 1인 경우 결과값의 크기 : {}\".format(output.size()))\n",
        "# 패딩 = 2\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=1, padding=2)\n",
        "output = conv_layer(image)\n",
        "plt.imshow(output[0,0,:,:].data.numpy(), cmap='gray')\n",
        "plt.show()\n",
        "print(\"패딩이 2인 경우 결과값의 크기 : {}\".format(output.size()))"
      ],
      "metadata": {
        "id": "kdlLKI8JTMhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lDSnP13oU621"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}